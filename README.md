![Model bias](./biased-model.jpeg)

# 들어가며
여기서는 __한국어 혐오표현 탐지 모델을 평가하고 편향을 밝혀내는 것__ 을 목적으로 합니다.
이를 위해 한국어 언어모델인 `KoBERT`를 '한국어 혐오표현 데이터셋'에 fine-tuning'하고, 
연구자가 직접 수집한 `Counter-speech` 데이터셋을 평가 데이터로 삼아 그 성능을 테스트했습니다. 

`Counter-speech`는 혐오표현에 대항, 반박하는 말들을 일컫는데, 예시로는 다음과 같은 것들이 있습니다.  

_"한국에서 생활하는 외국인들도 다 세금 내고 있다. 이 차별주의자야."_
_"성소수자는 대중 아니렴니까?"_

문제는, 이러한 표현들이 혐오표현에서 자주 쓰이는 키워드('성소수자', '차별', '외국인')를 사용하고 
때때로 공격적인 언사를 포함하는 까닭에 <mark>'혐오표현 탐지 모델'과 같은 것들이 이러한 표현들을 '혐오표현'으로 잘못 분류한다는 것입니다.</mark>
본 Repo는 이를 증명하고자 진행한 실험에 대한 기록입니다.

# 실험 결과

KoBERT 모델을 classification task로 fine-tuning 할 때 분류 정확도는 97.9%가 나왔습니다. 그러나 제가 구축한 `Counter-speech` 데이터셋에 평가해본 결과 정확도는 42.7%까지 하락했습니다. 이로서 <mark>한국어 혐오표현 탐지 모델이 특정한 키워드나 말투에 지나치게 민감하다</mark>고 판단할 수 있습니다. 자세한 내용과 사용한 데이터셋은 현재 논문 심사중에 있습니다. 